{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# __Machine Learning - Scale.__\n",
    "Date : 22, Feb, 2024.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Scale Features.__\n",
    "- When your data has different values, and even different measurement units, it can be difficult to compare them. \n",
    "\n",
    "- What is kilograms compared to meters? Or altitude compared to time?\n",
    "  \n",
    "    * The answer to this problem is scaling. We can scale data into new values that are easier to compare.\n",
    "       \n",
    "    * We take data-set called \"scaledata.csv\".\n",
    "    * where volume column contains values in liters instead of cm3 (1.0 instead of 1000)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Problem Statement and Procedure.__\n",
    "  \n",
    "- It can be difficult to compare the volume 1.0 with the weight 790, but if we scale them both into comparable values, we can easily see how much one value is compared to the other.\n",
    "\n",
    "- There are different methods for scaling data, in this tutorial we will use a method called __standardization__.\n",
    "\n",
    "- The standardization method uses this formula:\n",
    "\n",
    "    * __z = (x - u) / s__\n",
    "\n",
    "    - Where __z__ is the new value, __x__ is the original value, __u__ is the mean and __s__ is the standard deviation.\n",
    "\n",
    "- If you take the weight column from the data set above, the first value is 790, and the scaled value will be:\n",
    "\n",
    "    * (790 - 1292.23) / 238.74 = -2.1\n",
    "\n",
    "- If you take the volume column from the data set above, the first value is 1.0, and the scaled value will be:\n",
    "\n",
    "    * (1.0 - 1.61) / 0.38 = -1.59\n",
    "\n",
    "- Now you can compare -2.1 with -1.59 instead of comparing 790 with 1.0.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__StandardScaler().__\n",
    "\n",
    "- The Python sklearn module has a method called StandardScaler() which returns a Scaler object with methods for transforming data sets.\n",
    "\n",
    "- Example : Scale all values in the Weight and Volume columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-2.10389253 -1.59336644]\n",
      " [-0.55407235 -1.07190106]\n",
      " [-1.52166278 -1.59336644]\n",
      " [-1.78973979 -1.85409913]\n",
      " [-0.63784641 -0.28970299]\n",
      " [-1.52166278 -1.59336644]\n",
      " [-0.76769621 -0.55043568]\n",
      " [ 0.3046118  -0.28970299]\n",
      " [-0.7551301  -0.28970299]\n",
      " [-0.59595938 -0.0289703 ]\n",
      " [-1.30803892 -1.33263375]\n",
      " [-1.26615189 -0.81116837]\n",
      " [-0.7551301  -1.59336644]\n",
      " [-0.16871166 -0.0289703 ]\n",
      " [ 0.14125238 -0.0289703 ]\n",
      " [ 0.15800719 -0.0289703 ]\n",
      " [ 0.3046118  -0.0289703 ]\n",
      " [-0.05142797  1.53542584]\n",
      " [-0.72580918 -0.0289703 ]\n",
      " [ 0.14962979  1.01396046]\n",
      " [ 1.2219378  -0.0289703 ]\n",
      " [ 0.5685001   1.01396046]\n",
      " [ 0.3046118   1.27469315]\n",
      " [ 0.51404696 -0.0289703 ]\n",
      " [ 0.51404696  1.01396046]\n",
      " [ 0.72348212 -0.28970299]\n",
      " [ 0.8281997   1.01396046]\n",
      " [ 1.81254495  1.01396046]\n",
      " [ 0.96642691 -0.0289703 ]\n",
      " [ 1.72877089  1.01396046]\n",
      " [ 1.30990057  1.27469315]\n",
      " [ 1.90050772  1.01396046]\n",
      " [-0.23991961 -0.0289703 ]\n",
      " [ 0.40932938 -0.0289703 ]\n",
      " [ 0.47215993 -0.0289703 ]\n",
      " [ 0.4302729   2.31762392]]\n"
     ]
    }
   ],
   "source": [
    "import pandas \n",
    "from sklearn import linear_model\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scale=StandardScaler()\n",
    "df=pandas.read_csv('Files/scaledata.csv')\n",
    "X=df[['Weight', 'Volume']]\n",
    "scaledX=scale.fit_transform(X)\n",
    "print(scaledX)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Predict CO2 Values.__\n",
    "\n",
    "- When the data set is not scaled, we will have to use the scale when we predict values:\n",
    "\n",
    "- Example : Predict the CO2 emission from a 1.3 liter car that weighs 2300 kilograms:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[107.2087328]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asus\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas \n",
    "from sklearn import linear_model \n",
    "from sklearn.preprocessing import StandardScaler \n",
    "scale=StandardScaler()\n",
    "df=pandas.read_csv(\"Files/scaledata.csv\")\n",
    "X=df[['Weight', 'Volume']]\n",
    "y=df['CO2']\n",
    "scaledX=scale.fit_transform(X)\n",
    "regr=linear_model.LinearRegression()\n",
    "regr.fit(scaledX, y)\n",
    "scaled=scale.transform([[2300, 1.3]])\n",
    "predictedCO2=regr.predict(scaled)\n",
    "print(predictedCO2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotFittedError",
     "evalue": "This StandardScaler instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m X\u001b[38;5;241m=\u001b[39mdf[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWeight\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mVolume\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n\u001b[0;32m      7\u001b[0m y\u001b[38;5;241m=\u001b[39mdf[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCO2\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m----> 8\u001b[0m scaledX\u001b[38;5;241m=\u001b[39m\u001b[43mscale\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m regr\u001b[38;5;241m=\u001b[39mlinear_model\u001b[38;5;241m.\u001b[39mLinearRegression()\n\u001b[0;32m     10\u001b[0m regr\u001b[38;5;241m.\u001b[39mfit(scaledX, y)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\utils\\_set_output.py:295\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    293\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[0;32m    294\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 295\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    296\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    297\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    298\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    299\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m    300\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[0;32m    301\u001b[0m         )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\preprocessing\\_data.py:1040\u001b[0m, in \u001b[0;36mStandardScaler.transform\u001b[1;34m(self, X, copy)\u001b[0m\n\u001b[0;32m   1025\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtransform\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m   1026\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Perform standardization by centering and scaling.\u001b[39;00m\n\u001b[0;32m   1027\u001b[0m \n\u001b[0;32m   1028\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1038\u001b[0m \u001b[38;5;124;03m        Transformed array.\u001b[39;00m\n\u001b[0;32m   1039\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1040\u001b[0m     \u001b[43mcheck_is_fitted\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1042\u001b[0m     copy \u001b[38;5;241m=\u001b[39m copy \u001b[38;5;28;01mif\u001b[39;00m copy \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy\n\u001b[0;32m   1043\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(\n\u001b[0;32m   1044\u001b[0m         X,\n\u001b[0;32m   1045\u001b[0m         reset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1049\u001b[0m         force_all_finite\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow-nan\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1050\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\utils\\validation.py:1622\u001b[0m, in \u001b[0;36mcheck_is_fitted\u001b[1;34m(estimator, attributes, msg, all_or_any)\u001b[0m\n\u001b[0;32m   1619\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m is not an estimator instance.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (estimator))\n\u001b[0;32m   1621\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _is_fitted(estimator, attributes, all_or_any):\n\u001b[1;32m-> 1622\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m NotFittedError(msg \u001b[38;5;241m%\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mtype\u001b[39m(estimator)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m})\n",
      "\u001b[1;31mNotFittedError\u001b[0m: This StandardScaler instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator."
     ]
    }
   ],
   "source": [
    "import pandas \n",
    "from sklearn import linear_model \n",
    "from sklearn.preprocessing import StandardScaler \n",
    "scale=StandardScaler()\n",
    "df=pandas.read_csv(\"Files/scaledata.csv\")\n",
    "X=df[['Weight', 'Volume']]\n",
    "y=df['CO2']\n",
    "scaledX=scale.transform(X)\n",
    "regr=linear_model.LinearRegression()\n",
    "regr.fit(scaledX, y)\n",
    "scaled=scale.transform([[2300, 1.3]])\n",
    "predictedCO2=regr.predict(scaled)\n",
    "print(predictedCO2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
