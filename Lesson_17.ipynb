{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# __Machine Learning - Grid Search.__\n",
    "Date : 29, March, 2024."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The majority of machine learning models contain parameters that can be adjusted to vary how the model learns. \n",
    "\n",
    "- For example, the logistic regression model, from sklearn, has a parameter C that controls regularization, which affects the complexity of the model.\n",
    "How do we pick the best value for C? The best value is dependent on the data used to train the model.\n",
    "\n",
    "- One method is to try out different values and then pick the value that gives the best score. This technique is known as a grid search.\n",
    "\n",
    "- If we had to select the values for two or more parameters, we would evaluate all combinations of the sets of values thus forming a grid of values.\n",
    "\n",
    "- Before we get into the example it is good to know what the parameter we are changing does.\n",
    "    \n",
    "    * Higher values of C tell the model, the training data resembles real world information, place a greater weight on the training data.\n",
    "\n",
    "    * While lower values of C do the opposite.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Using Default Parameters.__\n",
    "\n",
    "- First let's see what kind of results we can generate without a grid search using only the base parameters.\n",
    "\n",
    "- Code : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(max_iter=10000)\n",
      "0.9733333333333334\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets \n",
    "from sklearn.linear_model import LogisticRegression \n",
    "\n",
    "iris= datasets.load_iris()\n",
    "# print(iris)\n",
    "X= iris['data']\n",
    "y= iris['target']\n",
    "\n",
    "logit= LogisticRegression(max_iter= 10000)\n",
    "print(logit.fit(X, y))\n",
    "print(logit.score(X, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Code Explanation.__\n",
    "\n",
    "- logit = LogisticRegression(max_iter=10000): \n",
    "\n",
    "    * This line initializes a logistic regression model object named logit. The max_iter parameter specifies the maximum number of iterations for the optimization algorithm to converge. Here, it's set to a high value (10000) to ensure convergence.\n",
    "\n",
    "- Keep in mind the default value for C in a logistic regression model is 1, we will compare this later.\n",
    "\n",
    "- print(logit.score(X, y)): \n",
    "    \n",
    "    * This line prints the accuracy score of the trained logistic regression model on the same data it was trained on. The score method calculates the accuracy by comparing the predicted labels with the actual labels in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the default setting of C = 1, we achieved a score of 0.973.    \n",
    "\n",
    "Let's see if we can do any better by implementing a grid search with difference values of 0.973."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
